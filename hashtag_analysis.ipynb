{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcCHc/xHX+28S65Sgs+dUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracek904/twitter-io/blob/main/hashtag_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jpjZw7f4BQv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import re\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib_venn import venn2\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data if not already downloaded\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('words', quiet=True)"
      ],
      "metadata": {
        "id": "rpASycQr6lUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "russia_df = pd.read_csv('/content/russia.csv')\n",
        "iran_df = pd.read_csv('/content/iran.csv')"
      ],
      "metadata": {
        "id": "eZ9l8cy06pn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only include English tweets\n",
        "russia_df = russia_df[russia_df['tweet_language'] == 'en']\n",
        "iran_df = iran_df[iran_df['tweet_language'] == 'en']"
      ],
      "metadata": {
        "id": "i5cFaUns66Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract and clean hashtags from each dataset\n",
        "def extract_hashtags(hashtags_column):\n",
        "    \"\"\"\n",
        "    Extract hashtags from the hashtags column.\n",
        "    Expects either a string representation of list or an actual list.\n",
        "    Returns a clean list of lowercase hashtags.\n",
        "    \"\"\"\n",
        "    all_hashtags = []\n",
        "\n",
        "    for entry in hashtags_column:\n",
        "        if pd.isna(entry) or entry == '[]' or entry == '':\n",
        "            continue\n",
        "\n",
        "        # Handle string representation of list\n",
        "        if isinstance(entry, str):\n",
        "            # Remove brackets, quotes, and split by comma\n",
        "            try:\n",
        "                # Try evaluating if it's a string representation of a list\n",
        "                hashtag_list = eval(entry)\n",
        "                if isinstance(hashtag_list, list):\n",
        "                    hashtags = hashtag_list\n",
        "                else:\n",
        "                    # If not a list, try to extract hashtags using regex\n",
        "                    hashtags = re.findall(r'#(\\w+)', entry)\n",
        "            except:\n",
        "                # If eval fails, try to extract hashtags using regex\n",
        "                hashtags = re.findall(r'#(\\w+)', entry)\n",
        "        elif isinstance(entry, list):\n",
        "            hashtags = entry\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Clean and lowercase all hashtags\n",
        "        cleaned_hashtags = [tag.lower() for tag in hashtags if tag]\n",
        "        all_hashtags.extend(cleaned_hashtags)\n",
        "\n",
        "    return all_hashtags"
      ],
      "metadata": {
        "id": "o1EzPIV468Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract hashtags from both datasets\n",
        "russia_hashtags = extract_hashtags(russia_df['hashtags'])\n",
        "iran_hashtags = extract_hashtags(iran_df['hashtags'])"
      ],
      "metadata": {
        "id": "Jc28E3sd6_dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count and sort hashtags by frequency\n",
        "russia_hashtag_counts = Counter(russia_hashtags)\n",
        "iran_hashtag_counts = Counter(iran_hashtags)\n",
        "\n",
        "# Get top 10 most frequent hashtags for each dataset\n",
        "top_russia_hashtags = russia_hashtag_counts.most_common(50)\n",
        "top_iran_hashtags = iran_hashtag_counts.most_common(50)\n",
        "\n",
        "print(\"\\nTop 50 Russia hashtags:\")\n",
        "for hashtag, count in top_russia_hashtags:\n",
        "    print(f\"#{hashtag}: {count}\")\n",
        "\n",
        "print(\"\\nTop 50 Iran hashtags:\")\n",
        "for hashtag, count in top_iran_hashtags:\n",
        "    print(f\"#{hashtag}: {count}\")"
      ],
      "metadata": {
        "id": "udUiH4Bg7C_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 30))  # Much taller figure to accommodate all 50 hashtags\n",
        "\n",
        "# Russia hashtags\n",
        "plt.subplot(1, 2, 1)\n",
        "russia_tags = [tag for tag, _ in top_russia_hashtags]\n",
        "russia_counts = [count for _, count in top_russia_hashtags]\n",
        "plt.barh(russia_tags, russia_counts, color='#3498db')\n",
        "plt.xlabel('Frequency', fontsize=12)\n",
        "plt.title('Top 50 Hashtags in Russian Dataset', fontsize=14)\n",
        "plt.gca().invert_yaxis()  # To have highest frequency at the top\n",
        "plt.tick_params(axis='y', labelsize=9)  # Slightly smaller font for labels\n",
        "\n",
        "# Iran hashtags\n",
        "plt.subplot(1, 2, 2)\n",
        "iran_tags = [tag for tag, _ in top_iran_hashtags]\n",
        "iran_counts = [count for _, count in top_iran_hashtags]\n",
        "plt.barh(iran_tags, iran_counts, color='#e74c3c')\n",
        "plt.xlabel('Frequency', fontsize=12)\n",
        "plt.title('Top 50 Hashtags in Iranian Dataset', fontsize=14)\n",
        "plt.gca().invert_yaxis()  # To have highest frequency at the top\n",
        "plt.tick_params(axis='y', labelsize=9)  # Slightly smaller font for labels\n",
        "\n",
        "plt.tight_layout(pad=3.0)  # Add padding between subplots\n",
        "plt.savefig('top_hashtags_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zpFAcgg07GkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a more sophisticated visualization using Plotly\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Top 10 Russia Hashtags\", \"Top 10 Iran Hashtags\"),\n",
        "                    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]])\n",
        "\n",
        "# Russia hashtags\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=[count for _, count in top_russia_hashtags],\n",
        "        y=[tag for tag, _ in top_russia_hashtags],\n",
        "        orientation='h',\n",
        "        marker=dict(color='blue'),\n",
        "        name='Russia'\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Iran hashtags\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=[count for _, count in top_iran_hashtags],\n",
        "        y=[tag for tag, _ in top_iran_hashtags],\n",
        "        orientation='h',\n",
        "        marker=dict(color='red'),\n",
        "        name='Iran'\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=\"Top Hashtags Comparison: Russia vs Iran Information Operations\",\n",
        "    height=500,\n",
        "    width=1000\n",
        ")\n",
        "\n",
        "fig.write_html(\"top_hashtags_comparison_interactive.html\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xwTn_uRX7Ju3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find common hashtags between the two datasets\n",
        "russia_set = set([tag for tag, _ in russia_hashtag_counts.most_common(50)])\n",
        "iran_set = set([tag for tag, _ in iran_hashtag_counts.most_common(50)])\n",
        "common_hashtags = russia_set.intersection(iran_set)\n",
        "\n",
        "print(f\"\\nNumber of common hashtags in top 50: {len(common_hashtags)}\")\n",
        "print(\"Common hashtags:\", sorted(list(common_hashtags)))"
      ],
      "metadata": {
        "id": "I7jKeNek7M8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Venn diagram of top 50 hashtags\n",
        "plt.figure(figsize=(10, 6))\n",
        "venn2([russia_set, iran_set], ('Russia (Top 50)', 'Iran (Top 50)'))\n",
        "plt.title('Common Hashtags in Top 50 Most Frequent')\n",
        "plt.savefig('common_hashtags_venn.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L8RgokVB7VNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a comparison bar chart for common hashtags\n",
        "if common_hashtags:\n",
        "    common_tags = list(common_hashtags)\n",
        "    russia_common_counts = [russia_hashtag_counts[tag] for tag in common_tags]\n",
        "    iran_common_counts = [iran_hashtag_counts[tag] for tag in common_tags]\n",
        "\n",
        "    # Sort by combined frequency\n",
        "    combined_counts = [(r+i, r, i, t) for r, i, t in zip(russia_common_counts, iran_common_counts, common_tags)]\n",
        "    combined_counts.sort(reverse=True)\n",
        "\n",
        "    # Take top 15 common hashtags by combined frequency\n",
        "    top_combined = combined_counts[:min(15, len(combined_counts))]\n",
        "\n",
        "    common_tags = [t for _, _, _, t in top_combined]\n",
        "    russia_common_counts = [r for _, r, _, _ in top_combined]\n",
        "    iran_common_counts = [i for _, _, i, _ in top_combined]\n",
        "\n",
        "    # Create grouped bar chart\n",
        "    x = np.arange(len(common_tags))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.figure(figsize=(14, 8)), plt.gca()\n",
        "\n",
        "    rects1 = ax.bar(x - width/2, russia_common_counts, width, label='Russia', color='#3498db')\n",
        "    rects2 = ax.bar(x + width/2, iran_common_counts, width, label='Iran', color='#e74c3c')\n",
        "\n",
        "    ax.set_title('Comparison of Common Hashtags Between Russia and Iran Datasets')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(common_tags, rotation=45, ha='right')\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('common_hashtags_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BiaBxVeA7W-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a normalized stacked bar chart to show relative usage\n",
        "normalized_data = pd.DataFrame({\n",
        "    'hashtag': common_tags,\n",
        "    'Russia': russia_common_counts,\n",
        "    'Iran': iran_common_counts\n",
        "})\n",
        "\n",
        "# Calculate total and percentages\n",
        "normalized_data['Total'] = normalized_data['Russia'] + normalized_data['Iran']\n",
        "normalized_data['Russia_pct'] = normalized_data['Russia'] / normalized_data['Total'] * 100\n",
        "normalized_data['Iran_pct'] = normalized_data['Iran'] / normalized_data['Total'] * 100\n",
        "\n",
        "# Sort by total frequency\n",
        "normalized_data = normalized_data.sort_values('Total', ascending=False)\n",
        "\n",
        "# Plot the percentages\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "plt.bar(normalized_data['hashtag'], normalized_data['Russia_pct'], color='#3498db', label='Russia')\n",
        "plt.bar(normalized_data['hashtag'], normalized_data['Iran_pct'], bottom=normalized_data['Russia_pct'],\n",
        "        color='#e74c3c', label='Iran')\n",
        "\n",
        "plt.xlabel('Hashtag')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Relative Usage of Common Hashtags')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('common_hashtags_relative_usage.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8oXZhaIp7Zxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network graph of co-occurring hashtags (optional advanced analysis)\n",
        "def extract_co_occurring_hashtags(df, hashtags_column, top_n=30):\n",
        "    \"\"\"Extract hashtags that co-occur in the same tweet.\"\"\"\n",
        "    co_occurrences = {}\n",
        "\n",
        "    for entry in df[hashtags_column]:\n",
        "        if pd.isna(entry) or entry == '[]' or entry == '':\n",
        "            continue\n",
        "\n",
        "        # Similar to extract_hashtags but returns a set of hashtags per tweet\n",
        "        try:\n",
        "            if isinstance(entry, str):\n",
        "                hashtag_list = eval(entry)\n",
        "                if isinstance(hashtag_list, list):\n",
        "                    hashtags = set(h.lower() for h in hashtag_list if h)\n",
        "                else:\n",
        "                    hashtags = set(h.lower() for h in re.findall(r'#(\\w+)', entry) if h)\n",
        "            elif isinstance(entry, list):\n",
        "                hashtags = set(h.lower() for h in entry if h)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            # Only consider tweets with multiple hashtags\n",
        "            if len(hashtags) > 1:\n",
        "                hashtags = list(hashtags)\n",
        "                for i in range(len(hashtags)):\n",
        "                    for j in range(i+1, len(hashtags)):\n",
        "                        pair = tuple(sorted([hashtags[i], hashtags[j]]))\n",
        "                        co_occurrences[pair] = co_occurrences.get(pair, 0) + 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Get top co-occurring pairs\n",
        "    top_pairs = sorted(co_occurrences.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    return top_pairs\n",
        "\n",
        "# This is optional and commented out as it requires additional libraries like networkx\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "# Extract co-occurring hashtags\n",
        "russia_co_occur = extract_co_occurring_hashtags(russia_df, 'hashtags')\n",
        "iran_co_occur = extract_co_occurring_hashtags(iran_df, 'hashtags')\n",
        "\n",
        "# Create network graphs\n",
        "def create_network_graph(co_occurrences, title):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add edges with weights\n",
        "    for (h1, h2), weight in co_occurrences:\n",
        "        G.add_edge(h1, h2, weight=weight)\n",
        "\n",
        "    # Calculate node sizes based on degree centrality\n",
        "    centrality = nx.degree_centrality(G)\n",
        "    node_sizes = [centrality[node] * 5000 for node in G.nodes()]\n",
        "\n",
        "    # Draw graph\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.8)\n",
        "    edges = nx.draw_networkx_edges(G, pos, width=[G[u][v]['weight']/5 for u, v in G.edges()],\n",
        "                                  alpha=0.5, edge_color='gray')\n",
        "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{title.replace(' ', '_').lower()}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "create_network_graph(russia_co_occur, \"Russia Hashtag Co-occurrence Network\")\n",
        "create_network_graph(iran_co_occur, \"Iran Hashtag Co-occurrence Network\")"
      ],
      "metadata": {
        "id": "y0NjEFSY7co5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}